{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10306866,"sourceType":"datasetVersion","datasetId":6380194}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install PySpark on Kaggle","metadata":{}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:29:35.665758Z","iopub.execute_input":"2024-12-26T23:29:35.666133Z","iopub.status.idle":"2024-12-26T23:30:16.581593Z","shell.execute_reply.started":"2024-12-26T23:29:35.666108Z","shell.execute_reply":"2024-12-26T23:30:16.580282Z"}},"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.4.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pyspark: filename=pyspark-3.5.4-py2.py3-none-any.whl size=317849765 sha256=c24f9898ad04125c7b50caa02f45c86e72412d623526a1b784f8aad25ab4aec1\n  Stored in directory: /root/.cache/pip/wheels/d9/1c/98/31e395a42d1735d18d42124971ecbbade844b50bb9845b6f4a\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.4\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Import necessary libraries\n","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nimport time\nfrom operator import add\nfrom collections import Counter\nfrom nltk.util import ngrams\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:11:20.310173Z","iopub.execute_input":"2024-12-27T01:11:20.310644Z","iopub.status.idle":"2024-12-27T01:11:21.901880Z","shell.execute_reply.started":"2024-12-27T01:11:20.310613Z","shell.execute_reply":"2024-12-27T01:11:21.900590Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# Part 1","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nspark =  SparkSession\\\n        .builder\\\n        .appName(\"Shahname\")\\\n        .getOrCreate()\n\n# Load Shahname\ninput_path = \"/kaggle/input/dmls-ca3/shahname.txt\"\n\nlines = spark.read.text(input_path).rdd.map(lambda r: r[0])\n\n# Count lines\ntotal_verses = lines.count()\nprint(f\"Total Verses: {total_verses}\")\n\n# Lines to words\ncounts = lines.flatMap(lambda x: x.split()) \\\n              .map(lambda x: (x, 1)) \\\n              .reduceByKey(add)\n# Count words\ntotal_words = counts.map(lambda x: x[1]).sum()\nunique_words = counts.count()\n\nprint(f\"Total Words: {int(total_words)}\")\nprint(f\"Unique Words: {unique_words}\")\nspark.stop()\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:59:02.156888Z","iopub.execute_input":"2024-12-26T23:59:02.157329Z","iopub.status.idle":"2024-12-26T23:59:05.038728Z","shell.execute_reply.started":"2024-12-26T23:59:02.157294Z","shell.execute_reply":"2024-12-26T23:59:05.037630Z"}},"outputs":[{"name":"stdout","text":"Total Verses: 51580\nTotal Words: 570849\nUnique Words: 18103\nTime: 2.87 seconds\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Without Spark","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\nwith open(\"/kaggle/input/dmls-ca3/shahname.txt\", \"r\", encoding=\"utf-8\") as file:\n    lines = file.readlines()\n\ntotal_verses = len(lines)\nprint(f\"Total Verses: {total_verses}\")\n\nwords = [word for line in lines for word in line.split()]\n\ntotal_words = len(words)\nprint(f\"Total Words: {total_words}\")\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T23:56:12.181427Z","iopub.execute_input":"2024-12-26T23:56:12.181808Z","iopub.status.idle":"2024-12-26T23:56:12.340251Z","shell.execute_reply.started":"2024-12-26T23:56:12.181774Z","shell.execute_reply":"2024-12-26T23:56:12.339145Z"}},"outputs":[{"name":"stdout","text":"Total Verses: 51580\nTotal Words: 570849\nTime: 0.15 seconds\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Part 2","metadata":{}},{"cell_type":"code","source":"def extract_rhyme(line):\n    if line.strip():  \n        words = line.split()\n        return words[-1]  # last word\n    return None  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:11:41.701512Z","iopub.execute_input":"2024-12-27T00:11:41.702052Z","iopub.status.idle":"2024-12-27T00:11:41.708514Z","shell.execute_reply.started":"2024-12-27T00:11:41.702013Z","shell.execute_reply":"2024-12-27T00:11:41.707260Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"start_time = time.time()\n\nspark =  SparkSession\\\n        .builder\\\n        .appName(\"Ghafieh\")\\\n        .getOrCreate()\n\n# Load Shahname\ninput_path = \"/kaggle/input/dmls-ca3/shahname.txt\"\n\nlines = spark.read.text(input_path).rdd.map(lambda row: row[0])\n\n# Last words\nrhymes = lines.map(extract_rhyme)\n\n# Count \ncounts = rhymes.filter(lambda rhyme: rhyme is not None) \\\n                     .map(lambda rhyme: (rhyme, 1)) \\\n                     .reduceByKey(add)\n\n# Top 10\ntop_rhymes = counts.takeOrdered(10, key=lambda x: -x[1])\n\nprint(\"Top 10 Frequent Rhymes:\")\nfor rhyme, count in top_rhymes:\n    print(f\"{rhyme}: {count}\")\n\nspark.stop()\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:19:52.501778Z","iopub.execute_input":"2024-12-27T00:19:52.502213Z","iopub.status.idle":"2024-12-27T00:19:55.228430Z","shell.execute_reply.started":"2024-12-27T00:19:52.502159Z","shell.execute_reply":"2024-12-27T00:19:55.227277Z"}},"outputs":[{"name":"stdout","text":"Top 10 Frequent Rhymes:\nبود: 881\nسپاه: 632\nراه: 518\nشاه: 463\nاوی: 423\nکرد: 412\nرا: 385\nروی: 381\nشد: 363\nزمین: 338\nTime: 2.72 seconds\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### Without Spark","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\n# Load the text file\nwith open(input_path, \"r\", encoding=\"utf-8\") as file:\n    lines = file.readlines()\n\nrhymes = [extract_rhyme(line) for line in lines if extract_rhyme(line) is not None]\n\nrhyme_counts = Counter(rhymes)\n\ntop_rhymes = rhyme_counts.most_common(10)\n\nprint(\"Top 10 Frequent Rhymes:\")\nfor rhyme, count in top_rhymes:\n    print(f\"{rhyme}: {count}\")\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T00:20:23.132124Z","iopub.execute_input":"2024-12-27T00:20:23.132486Z","iopub.status.idle":"2024-12-27T00:20:23.304951Z","shell.execute_reply.started":"2024-12-27T00:20:23.132462Z","shell.execute_reply":"2024-12-27T00:20:23.303933Z"}},"outputs":[{"name":"stdout","text":"Top 10 Frequent Rhymes:\nبود: 881\nسپاه: 632\nراه: 518\nشاه: 463\nاوی: 423\nکرد: 412\nرا: 385\nروی: 381\nشد: 363\nزمین: 338\nTime: 0.17 seconds\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Part 3","metadata":{}},{"cell_type":"markdown","source":"### Function for 3-gram","metadata":{}},{"cell_type":"code","source":"def map_to_trigrams(line):\n    words = line.split()  \n    trigrams = []  \n    if len(words) < 3:  \n        return trigrams\n    for i in range(len(words) - 2):  \n        trigram = words[i] + \" \" + words[i+1] + \" \" + words[i+2]\n        trigrams.append((trigram, 1))  \n    return trigrams","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:07:57.639148Z","iopub.execute_input":"2024-12-27T01:07:57.639529Z","iopub.status.idle":"2024-12-27T01:07:57.645267Z","shell.execute_reply.started":"2024-12-27T01:07:57.639500Z","shell.execute_reply":"2024-12-27T01:07:57.643985Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"start_time = time.time()\n\nspark =  SparkSession\\\n        .builder\\\n        .appName(\"trigram\")\\\n        .getOrCreate()\n\n# Load Shahname\ninput_path = \"/kaggle/input/dmls-ca3/shahname.txt\"\nlines = spark.read.text(input_path).rdd.map(lambda row: row[0])\nlines = lines.filter(lambda line: line.strip() != \"\")\n\ntrigram_counts = lines.flatMap(map_to_trigrams) \\\n                      .reduceByKey(add)\n\ntotal_trigrams = trigram_counts.count()\nprint(f\"Total 3-grams: {total_trigrams}\")\n\n# Top 10 \ntop_trigrams = trigram_counts.takeOrdered(10, key=lambda x: -x[1])\nprint(\"Top 10 Frequent 3-grams:\")\nfor trigram, count in top_trigrams:\n    print(f\"{trigram}: {count}\")\n\nspark.stop()\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:18:37.170074Z","iopub.execute_input":"2024-12-27T01:18:37.170469Z","iopub.status.idle":"2024-12-27T01:18:41.860935Z","shell.execute_reply.started":"2024-12-27T01:18:37.170440Z","shell.execute_reply":"2024-12-27T01:18:41.859575Z"}},"outputs":[{"name":"stdout","text":"Total 3-grams: 363060\nTop 10 Frequent 3-grams:\nچنین داد پاسخ: 390\nداد پاسخ که: 283\nچنین گفت با: 188\nچنین گفت کای: 185\nمر او را: 165\nبدو گفت کای: 155\nتاج و تخت: 145\nز هر سو: 126\nنشست از بر: 124\nفرود آمد از: 114\nTime: 4.68 seconds\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"### Using NLTK","metadata":{}},{"cell_type":"code","source":"# Start measuring time\nstart_time = time.time()\n\n# Load Shahname text file\nwith open(input_path, \"r\", encoding=\"utf-8\") as file:\n    lines = file.readlines()\n\nall_trigrams = []\nfor line in lines:\n    words = line.split()\n    if len(words) >= 3: \n        trigrams = ngrams(words, 3)  \n        all_trigrams.extend(trigrams)\n\ntrigram_counts = Counter(all_trigrams)\n\ntotal_trigrams = sum(trigram_counts.values())\nprint(f\"Total 3-grams: {total_trigrams}\")\n\ntop_trigrams = trigram_counts.most_common(10)\nprint(\"Top 10 Frequent 3-grams:\")\nfor trigram, count in top_trigrams:\n    print(f\"{' '.join(trigram)}: {count}\")\n\nend_time = time.time()\nprint(f\"Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:19:47.832097Z","iopub.execute_input":"2024-12-27T01:19:47.832547Z","iopub.status.idle":"2024-12-27T01:19:48.444959Z","shell.execute_reply.started":"2024-12-27T01:19:47.832514Z","shell.execute_reply":"2024-12-27T01:19:48.443927Z"}},"outputs":[{"name":"stdout","text":"Total 3-grams: 470275\nTop 10 Frequent 3-grams:\nچنین داد پاسخ: 390\nداد پاسخ که: 283\nچنین گفت با: 188\nچنین گفت کای: 185\nمر او را: 165\nبدو گفت کای: 155\nتاج و تخت: 145\nز هر سو: 126\nنشست از بر: 124\nفرود آمد از: 114\nTime: 0.61 seconds\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}